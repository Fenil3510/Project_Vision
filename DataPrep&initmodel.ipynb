{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPrep&initmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZBo464rMgKbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "404a068c-3fcd-446f-86e5-b12ae5925d3c"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmplpmqhjxc/pubring.gpg' created\n",
            "gpg: /tmp/tmplpmqhjxc/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ffpGkKIgmHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jv3IXaF1g-Te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fb929c4f-3906-42ff-e3dc-52e0b7135df3"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Z3etctthNJq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p car_vision\n",
        "!google-drive-ocamlfuse car_vision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Giz6bfGGiNLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "from shutil import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-DQb_nraiIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "c2c3c411-62bb-4839-a65b-b5d85f4b6b02"
      },
      "cell_type": "code",
      "source": [
        "!pip install imgaug"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imgaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.19.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.11.0)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (4.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (0.5.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.1)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.1.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image>=0.11.0->imgaug) (0.45.1)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2018.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2.2.0)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Running setup.py bdist_wheel for imgaug ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "Successfully installed imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QY_Wnz0OoDLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "90556293-0359-4c43-b0ba-0bb08671a5ff"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XPMvZT736vVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSRurBYczbNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def yolo_to_x_y(x_center, y_center, x_width, y_height, width, height):\n",
        "    x_center *= width\n",
        "    y_center *= height\n",
        "    x_width *= width\n",
        "    y_height *= height\n",
        "    return x_center - x_width/2, y_center - y_height/2, x_width, y_height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AS7Qj1Kj0Tvo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "coordinates_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7v-a5Ld1lX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "885ed3f1-e3e2-4479-f787-1ef5d0a8f420"
      },
      "cell_type": "code",
      "source": [
        "#Not tun\n",
        "for boxes in tqdm(bounding_boxes):\n",
        "  with open('car_vision/bounding_boxes/' + boxes) as f:\n",
        "      k = f.read()[:-1]\n",
        "      for coords in k.split(' '):\n",
        "          coordinates_list.append(float(coords))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9294cd308fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'car_vision/bounding_boxes/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mcoordinates_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bounding_boxes' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7BbNk2BsN8ez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_l3_btxfOC7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sys.path.append('car_vision/keras-yolo2/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "im2rpXNaNj-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "412bb9f7-dbe4-4a32-825f-f6af0335614d"
      },
      "cell_type": "code",
      "source": [
        "#Main libraries\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.merge import concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import imgaug as ia\n",
        "from tqdm import tqdm\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os, cv2\n",
        "from preprocessing import parse_annotation, BatchGenerator\n",
        "from utils import WeightReader, decode_netout, draw_boxes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "itjhMAF-O2JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f196563b-6041-4f0e-cb9c-7ffdeac977f7"
      },
      "cell_type": "code",
      "source": [
        "#bbox_xml\n",
        "final_labeled_images_resized_512 = []\n",
        "for images in tqdm(os.listdir('car_vision/images_labelled_512/')):\n",
        "  final_labeled_images_resized_512.append(plt.imread('car_vision/images_labelled_512/'+ images))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1793/1793 [19:53<00:00,  1.50it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dOBk_voSPR2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Will do later. I unlabelled files also need xml form.\n",
        "final_unlabeled_images_resized_512 = []\n",
        "for images in tqdm(unlabelled):\n",
        "  final_unlabeled_images_resized_512.append(plt.imread(images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ePh4dXUqyvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LABELS = ['0']\n",
        "\n",
        "IMAGE_H, IMAGE_W = 512, 512\n",
        "GRID_H,  GRID_W  = 16 , 16\n",
        "BOX              = 5\n",
        "CLASS            = len(LABELS)\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
        "OBJ_THRESHOLD    = 0.5\n",
        "NMS_THRESHOLD    = 0.5\n",
        "ANCHORS          = [1.33,3.52, 5.44,5.50, 6.46,7.97, 10.20,5.71, 11.90,12.51]\n",
        "\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "CLASS_SCALE      = 1.0\n",
        "\n",
        "BATCH_SIZE       = 16\n",
        "WARM_UP_BATCHES  = 3\n",
        "TRUE_BOX_BUFFER  = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJr1oYbzyQaa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wt_path = \"car_vision/yolo.weights\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aypGnUssydQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_config = {\n",
        "    'IMAGE_H'         : IMAGE_H, \n",
        "    'IMAGE_W'         : IMAGE_W,\n",
        "    'GRID_H'          : GRID_H,  \n",
        "    'GRID_W'          : GRID_W,\n",
        "    'BOX'             : BOX,\n",
        "    'LABELS'          : LABELS,\n",
        "    'CLASS'           : len(LABELS),\n",
        "    'ANCHORS'         : ANCHORS,\n",
        "    'BATCH_SIZE'      : BATCH_SIZE,\n",
        "    'TRUE_BOX_BUFFER' : 1,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VADjTixHhP6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7cbc96a-daa6-4149-dc0f-f59c8b283bb9"
      },
      "cell_type": "code",
      "source": [
        "np.max(final_labeled_images_resized_512[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "ni-KsrcJqUqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Scaling the images\n",
        "def  normalize(image):\n",
        "    return image/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQ5lirHjTbtK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path = 'car_vision/images_labelled_512/'\n",
        "annot_path = 'car_vision/bounding_box_xml_512/'\n",
        "\n",
        "all_imgs, seen_labels = parse_annotation(annot_path, image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGakWs7SThEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add extensions to image name\n",
        "for img in all_imgs:\n",
        "    img['filename'] = img['filename'][:-4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FggZSBO-VcIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "db8813de-ba4b-4425-afc1-cb0280b1f397"
      },
      "cell_type": "code",
      "source": [
        "all_imgs[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'filename': 'car_vision/images_labelled_512/0 (1).jpg.xml',\n",
              " 'height': 512,\n",
              " 'object': [{'name': '0', 'xmax': 409, 'xmin': 104, 'ymax': 446, 'ymin': 268}],\n",
              " 'width': 512}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "j_DO6bq6qdp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_split = int(0.8*len(final_labeled_images_resized_512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TToTdQcab5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRbtl2tbatnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??np.random.shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EjRzrAQaOLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_imgs = np.array(all_imgs)\n",
        "np.random.shuffle(all_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8lz-_fHRqiSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_batch = BatchGenerator(all_imgs[:train_valid_split], generator_config)\n",
        "valid_batch = BatchGenerator(all_imgs[train_valid_split:], generator_config, norm=normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRqtFq7_qwHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrarKdmNrJNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_image  = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
        "\n",
        "# Layer 1\n",
        "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=True)(input_image)\n",
        "x = BatchNormalization(name='norm_1')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 2\n",
        "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_2')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 3\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_3')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 4\n",
        "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_4')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 5\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_5')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 6\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_6')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 7\n",
        "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_7')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 8\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=True, input_shape=(416,416,3))(x)\n",
        "x = BatchNormalization(name='norm_8')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 9\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_9')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 10\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_10')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 11\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_11')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 12\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_12')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 13\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_13')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "skip_connection = x\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 14\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14',use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_14')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 15\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_15')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 16\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_16')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 17\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_17')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 18\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_18')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 19\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_19')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 20\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_20')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 21\n",
        "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21',use_bias=True)(skip_connection)\n",
        "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "x = concatenate([skip_connection, x])\n",
        "\n",
        "# Layer 22\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=True)(x)\n",
        "x = BatchNormalization(name='norm_22')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 23\n",
        "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
        "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
        "\n",
        "# small hack to allow true_boxes to be registered when Keras build the model \n",
        "# for more information: https://github.com/fchollet/keras/issues/2790\n",
        "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
        "\n",
        "model = Model([input_image, true_boxes], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdVGH0EYA3pz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_reader = WeightReader(\"car_vision/yolo.weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wIJNBAK-HGic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2822
        },
        "outputId": "78bc6435-da97-403c-c459-b43efef4337f"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 512, 512, 32) 896         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 512, 512, 32) 128         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, 512, 512, 32) 0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 256, 256, 32) 0           leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 256, 256, 64) 18496       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 256, 256, 64) 256         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, 256, 256, 64) 0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 128, 128, 64) 0           leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 128, 128, 128 73856       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 128, 128, 128 512         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, 128, 128, 128 0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 128, 128, 64) 8256        leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 128, 128, 64) 256         conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, 128, 128, 64) 0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 128, 128, 128 73856       leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 128, 128, 128 512         conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, 128, 128, 128 0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 128)  0           leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, 64, 64, 256)  295168      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 64, 64, 256)  1024        conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, 64, 64, 256)  0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, 64, 64, 128)  32896       leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 64, 64, 128)  512         conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, 64, 64, 128)  0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_8 (Conv2D)                 (None, 64, 64, 256)  295168      leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 64, 64, 256)  1024        conv_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, 64, 64, 256)  0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 256)  0           leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, 32, 32, 512)  1180160     max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 32, 32, 512)  2048        conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, 32, 32, 512)  0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, 32, 32, 256)  131328      leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_10 (BatchNormalization)    (None, 32, 32, 256)  1024        conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, 32, 32, 256)  0           norm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_11 (Conv2D)                (None, 32, 32, 512)  1180160     leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_11 (BatchNormalization)    (None, 32, 32, 512)  2048        conv_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, 32, 32, 512)  0           norm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_12 (Conv2D)                (None, 32, 32, 256)  131328      leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_12 (BatchNormalization)    (None, 32, 32, 256)  1024        conv_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, 32, 32, 256)  0           norm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, 32, 32, 512)  1180160     leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 32, 32, 512)  2048        conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, 32, 32, 512)  0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 512)  0           leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_14 (Conv2D)                (None, 16, 16, 1024) 4719616     max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_14 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_15 (Conv2D)                (None, 16, 16, 512)  524800      leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_15 (BatchNormalization)    (None, 16, 16, 512)  2048        conv_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, 16, 16, 512)  0           norm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, 16, 16, 1024) 4719616     leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_16 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, 16, 16, 512)  524800      leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_17 (BatchNormalization)    (None, 16, 16, 512)  2048        conv_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, 16, 16, 512)  0           norm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_18 (Conv2D)                (None, 16, 16, 1024) 4719616     leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_18 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_19 (Conv2D)                (None, 16, 16, 1024) 9438208     leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_19 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_21 (Conv2D)                (None, 32, 32, 64)   32832       leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_21 (BatchNormalization)    (None, 32, 32, 64)   256         conv_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_20 (Conv2D)                (None, 16, 16, 1024) 9438208     leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, 32, 32, 64)   0           norm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_20 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 16, 16, 256)  0           leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 1280) 0           lambda_5[0][0]                   \n",
            "                                                                 leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_22 (Conv2D)                (None, 16, 16, 1024) 11797504    concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_22 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_23 (Conv2D)                (None, 16, 16, 30)   30750       leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 16, 16, 5, 6) 0           conv_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 1, 1, 1, 1, 4 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 16, 16, 5, 6) 0           reshape_3[0][0]                  \n",
            "                                                                 input_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,589,022\n",
            "Trainable params: 50,568,350\n",
            "Non-trainable params: 20,672\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BKj9ZM6UH4T4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_reader.reset()\n",
        "nb_conv = 23\n",
        "\n",
        "for i in range(1, nb_conv+1):\n",
        "    conv_layer = model.get_layer('conv_' + str(i))\n",
        "    \n",
        "    if i < nb_conv:\n",
        "        norm_layer = model.get_layer('norm_' + str(i))\n",
        "        \n",
        "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "        beta  = weight_reader.read_bytes(size)\n",
        "        gamma = weight_reader.read_bytes(size)\n",
        "        mean  = weight_reader.read_bytes(size)\n",
        "        var   = weight_reader.read_bytes(size)\n",
        "\n",
        "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
        "        \n",
        "    if len(conv_layer.get_weights()) > 1:\n",
        "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "        kernel = kernel.transpose([2,3,1,0])\n",
        "        conv_layer.set_weights([kernel, bias])\n",
        "    else:\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "        kernel = kernel.transpose([2,3,1,0])\n",
        "        conv_layer.set_weights([kernel])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUzK_kfDJxA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer = model.layers[-4] # the last convolutional layer\n",
        "weights = layer.get_weights()\n",
        "\n",
        "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\n",
        "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n",
        "\n",
        "layer.set_weights([new_kernel, new_bias])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYgi02L0J-zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  custom_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "    \n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
        "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
        "    \n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    class_mask = tf.zeros(mask_shape)\n",
        "    \n",
        "    seen = tf.Variable(0.)\n",
        "    total_recall = tf.Variable(0.)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    ### adjust x and y      \n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    \n",
        "    ### adjust w and h\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
        "    \n",
        "    ### adjust confidence\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    pred_box_class = y_pred[..., 5:]\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    ### adjust x and y\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "    \n",
        "    ### adjust w and h\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "    \n",
        "    ### adjust confidence\n",
        "    true_wh_half = true_box_wh / 2.\n",
        "    true_mins    = true_box_xy - true_wh_half\n",
        "    true_maxes   = true_box_xy + true_wh_half\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    \n",
        "    true_box_conf = iou_scores * y_true[..., 4]\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "    \n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
        "    \n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "    true_xy = true_boxes[..., 0:2]\n",
        "    true_wh = true_boxes[..., 2:4]\n",
        "    \n",
        "    true_wh_half = true_wh / 2.\n",
        "    true_mins    = true_xy - true_wh_half\n",
        "    true_maxes   = true_xy + true_wh_half\n",
        "    \n",
        "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "    \n",
        "    pred_wh_half = pred_wh / 2.\n",
        "    pred_mins    = pred_xy - pred_wh_half\n",
        "    pred_maxes   = pred_xy + pred_wh_half    \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
        "    \n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
        "    \n",
        "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
        "    \n",
        "    \"\"\"\n",
        "    Warm-up training\n",
        "    \"\"\"\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
        "    seen = tf.assign_add(seen, 1.)\n",
        "    \n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
        "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
        "                                   tf.ones_like(coord_mask)],\n",
        "                          lambda: [true_box_xy, \n",
        "                                   true_box_wh,\n",
        "                                   coord_mask])\n",
        "    \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "    \n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "    \n",
        "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
        "    \n",
        "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "\n",
        "    \"\"\"\n",
        "    Debugging code\n",
        "    \"\"\"    \n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "    total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXA3jyRqLKd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           min_delta=0.001, \n",
        "                           patience=3, \n",
        "                           mode='min', \n",
        "                           verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights_blood.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "232pza60LQFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tb_countertb_coun   = len([log for log in os.listdir(os.path.expanduser('~/logs/')) if 'blood' in log]) + 1\n",
        "#tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/') + 'blood' + '_' + str(tb_counter), \n",
        "#                         histogram_freq=0, \n",
        "#                          write_graph=True, \n",
        "#                          write_images=False)\n",
        "\n",
        "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
        "#optimizer = RMSprop(lr=1e-5, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss=custom_loss, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VSvlMj9wfDPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "2e8f1035-003d-4f2c-90a6-6e25c18e1e34"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(\"car_vision/yolo.weights\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-a56d8e7d6a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"car_vision/yolo.weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "FYNlS63dcD8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9bf7f1be-8887-4b4e-d348-f45bc455df19"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator        = train_batch, \n",
        "                    steps_per_epoch  = len(train_batch), \n",
        "                    epochs           = 100, \n",
        "                    verbose          = 1,\n",
        "                    validation_data  = valid_batch,\n",
        "                    validation_steps = len(valid_batch),\n",
        "                    callbacks        = [early_stop, checkpoint], \n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "90/90 [==============================] - 144s 2s/step - loss: 0.0392 - val_loss: 1.5238\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.52377, saving model to weights_blood.h5\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 133s 1s/step - loss: 0.4940 - val_loss: 14.0876\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.52377\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 132s 1s/step - loss: 0.1376 - val_loss: 4.9354\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.52377\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 134s 1s/step - loss: 0.1028 - val_loss: 5.9866\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.52377\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01e9e74e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "bKt5EGwTeMg-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}